# 0 模型基本信息

数据集: 
1. 内窥镜引导下的胆囊切除手术视频流程识别数据集
2. 有7种手术动作及7种手术工具的标注
3. 80段视频共计370168张, 每隔25帧采样一张图像, 按照1:1的比例划分为训练集和测试集
4. 完整数据确实有75到93GB, 需要的话可以看看这两个链接都可以下载(官网那个需要申请): 
https://www.kaggle.com/datasets/swamysaxena09/cholec80 (未打包可分开下, 有tool和phase的标注)和 https://github.com/CAMMA-public/TF-Cholec80 (已做打包, 只能整体下)

7种手术动作:
* Preparation
* CalotTriangleDissection
* ClippingCutting
* GallbladderDissection
* GallbladderRetraction
* CleaningCoagulation
* GallbladderPackaging

7中手术工具:
* Grasper
* Bipolar
* Hook
* Scissors
* Clipper
* Irrigator
* SpecimenBag


模型:
1. 多任务模型(分类模型)
    1. 任务一: 识别手术动作
    2. 任务二: 识别手术工具


2. 模型基本结构(详细见原库中的网络结构图和其论文)
    1. 预训练的resnet50提取特征图
    2. 接全连接网络输出预测手术工具
    3. 序列数据进入LSTM预测手术动作


# 1 跑模型步骤

挂载gpu资源
1. ``salloc -N 1 -n 4 -p g078t1 --gres=gpu:2 --comment by2010813734``
2. ``ssh ${对应的node名}``
    1. 可``squeue``查看node使用信息

切换conda环境
1. 可使用的conda环境为mtrcnet_torch6 
    1. 全部环境可用``conda env list`` 查看
2. ``source activate mtrcnet_torch6``
    1. 激活mtrcnet_torch6环境
    2. 成功后在命令行前显示``(mtrcnet_torch6)``

进入模型文件夹
1. ``cd /home/u2022141214/mtr_20240709 ``
    1. demo数据放在``cholec``目录下

生成训练集, 验证集和测试集, 命令如下:
- ``python get_paths_labels.py``
    - 产出文件名为``cholec80.pkl``, 里面保存了相关数据的信息

模型训练, 命令如下:
1. ``python train_singlenet_tool.py``
    1. 仅训练手术工具识别, 产出模型以cnn_lstm_tool_epoch开头(后缀为.pth)
2. ``python train_mtrcnet.py``
    1. 手术工具和手术动作同时识别, 产出模型以cnn_lstm_epoch开头(后缀为.pth)
3. ``python train_singlenet_phase.py``
    1. 仅训练手术动作识别, 产出模型以lstm_phase_epoch开头(后缀为.pth)

模型测试, 命令如下:
1. ``python test_singlenet_tool.py --name ${模型名字}``
    1. 测试手术工具识别模型的效果
    2. 类似: ``python test_singlenet_tool.py --name cnn_lstm_tool_epoch_2_length_1_opt_1_mulopt_1_flip_0_crop_1_batch_1_train1_10000_val1_0.pth``
2. ``python test_singlenet_phase.py --name  ${模型名字}`` 
    1. 测试手术动作识别模型的效果
    2. 类似 ``python test_singlenet_phase.py --name lstm_phase_epoch_2_length_1_opt_1_mulopt_1_flip_0_crop_1_batch_1_train_10000_val_10000.pth``
3. ``python test_mtrcnet.py --name  ${模型名字}`` 
    1. 测试手术动作识别模型的效果
    2. 类似 ``python test_mtrcnet.py --name cnn_lstm_epoch_2_length_1_opt_1_mulopt_1_flip_0_crop_1_batch_1_train1_10000_train2_10000_val1_10000_val2_10000.pth``

导出模型预测结果, 命令如下:
1. ``python export_tool.py --name ${模型名字}`` 
    1. 导出手术工具识别模型的预测结果
    2. 类似: ``python export_tool.py --name cnn_lstm_tool_epoch_2_length_1_opt_1_mulopt_1_flip_0_crop_1_batch_1_train1_10000_val1_0_test1_10000_crop_1.pkl``
2. ``python export_phase.py --name ${模型名字}`` 
    1. 导出手术动作识别模型的预测结果
    2. 类似: ``python export_phase.py --name lstm_phase_epoch_2_length_1_opt_1_mulopt_1_flip_0_crop_1_batch_1_train_10000_val_10000_test_10000_crop_1.pkl``

# 二 环境配置信息
miniconda镜像源
1. ``~/.condarc``文件里(官网https的速度特别慢, 这里更改成了http)
    ```
    channels:
        - defaults
    show_channel_urls: true
    default_channels:
        - http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
        - http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r
        - http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2
    custom_channels:
        conda-forge: http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
        msys2: http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud                                                                                   
        bioconda: http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
        menpo: http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
        pytorch: http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
        pytorch-lts: http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
        simpleitk: http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
        deepmodeling: http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/
    ```

conda环境
- 版本及安装命令
    ```
    conda create --name mtrcnet_torch6 pytorch=2.0.1=gpu_cuda118py38he342708_0 torchvision=0.15.2 pillow=8.3.1
    ```

# 三 过程中遇到的点
1. 镜像源速度慢的问题(见上)
2. cuda版本的匹配问题
    1. 环境中使用的是11.8, 装pytorch, torchvision时需要注意
3. Pillow版本问题
4. 训练时最好按照顺序采样
    1. 代码中默认了顺序排列的索引, 且会按照这个取数据
    2. 模型中有LSTM模块, 随机采可能会导致两个不同的序列排在一起
4. 如果要简化数据, 可以从每秒25张 变为5张, 1张
    1. 做了下采样需要删掉对应的phase和tool标注
5. GPU资源貌似有时间限制, 一会儿就收了
    